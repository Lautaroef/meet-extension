# Task ID: 28
# Title: Refine GEM Alert Intelligence (Contextual Gemini via Backend)
# Status: pending
# Dependencies: 26, 27, 20, 13, 19
# Priority: high
# Description: Enhance the 'GEM' alert intelligence by using Google's Gemini models via a backend service to analyze the live transcript in conjunction with synced user data, moving beyond simple keyword spotting to detect more nuanced contextual connections.
# Details:
1. This task builds upon the GEM identification mechanism in Task 21 and the prompt engineering in Task 27.
2. The Next.js backend service (Subtask 19.4) will be called with transcript segments.
3. The backend service will use refined prompts (from Task 27, iterated here) to query the Gemini API.
4. These prompts will instruct Gemini to perform a more sophisticated analysis of the transcript segment, cross-referencing it with a richer set of synced user data (Task 13) to identify subtle connections, anticipate needs, or flag complex action items.
5. Requests to Gemini should continue to specify structured JSON output to clearly delineate identified GEMs and their attributes.
6. Focus on optimizing the prompt and potentially the amount/type of context sent to Gemini to achieve low latency suitable for real-time alerts while maximizing the insightfulness of the GEMs.
7. The extension background script will process the structured JSON from the backend to trigger/update GEM alerts.

# Test Strategy:
Test with diverse meeting scenarios. Compare Gemini-driven GEMs against keyword-based ones. Evaluate relevance and insightfulness. Test the interaction between the extension, backend service, and Gemini API. Monitor Gemini API usage, latency, and overall performance. Verify correct processing of structured JSON responses.
